{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision and Recall\n",
    "\n",
    "In machine learning model, we have mentioned that, there is an important concept called metrics. However, for classifications problems, accuracy is one of the metrics. There are other important metrics.\n",
    "\n",
    "In this exercise, we will test our model with new metrics: Precision and Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Please answer Questions\n",
    "\n",
    "To help you understand precision and recall. Please answer questions below by searching and input your answers.\n",
    "\n",
    "* **Question 1: What is your understanding of these terms: true postive, false postive, true negative, false negative?**\n",
    "    <br>\n",
    "    True positive : pedicted and actual conditions both are positive <br>\n",
    "    False positive : predicted condition positive but actual condition negative <br>\n",
    "    True negative : predicted and actual conditions both negative <br>\n",
    "    False negative : predicted condition negative but actual condition positive\n",
    "\n",
    "* **Question 2: What are the relationships between those terms and precision or recall?**\n",
    "    <br>\n",
    "    Precision = (true positive)/(true positive + false positive) <br>\n",
    "    Recall = (true positive)/(true positive + false negative)\n",
    "\n",
    "* Please write down your answer by two simple methematical equation\n",
    "\n",
    "** Answer:** Please double click the cell and input your answer here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below is an example for how to get precision of your model\n",
    "\n",
    "** Attention **: You need to finish one line of code to implement the whole example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's load iris data again\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's split the data to training and testing data.\n",
    "random_state = np.random.RandomState(0)\n",
    "n_samples, n_features = X.shape\n",
    "X = np.c_[X, random_state.randn(n_samples, 200 * n_features)]\n",
    "\n",
    "# Limit to the two first classes, and split into training and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[y < 2], y[y < 2],\n",
    "                                                    test_size=.5,\n",
    "                                                    random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple classifier\n",
    "classifier = svm.LinearSVC(random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2',\n",
       "     random_state=<mtrand.RandomState object at 0xadf95e3c>, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After you have fit the model, then we make predicions.\n",
    "y_score = classifier.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the average precision score, Run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision-recall score: 0.88\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "average_precision = average_precision_score(y_test, y_score)\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
